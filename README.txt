DeepSquat is a project that I and another team member (Seyoon Ragavan) worked on for Hack Princeton Fall 2017. It is an app that allows the user to take a video of their squat, and analyzes six specific attributes of their squat technique using deep learning. We were recognized as "Best Health/Fitness Hack" and named a Finalist (one of the Top 7 projects).

Acknowledgement of people whose public code (published online) was used:

M.I. Hollemans (on GitHub): CoreMLHelpers library
Boris Ohayon (for Medium): code to process the video frame by frame as it is being captured
Jeff Rames (for raywenderlich.com): code to detect and trigger the necessary events when the user says “start” and “stop” (live speech recognition)

The model files were too large to push to Github, but they can be found here: https://drive.google.com/drive/u/1/folders/1eghAWiQ6Bk1xfJk5E3H9IrvjdyV2evS0
